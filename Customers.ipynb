{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35b00aa",
   "metadata": {},
   "source": [
    "# **TASKS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304ee551",
   "metadata": {},
   "source": [
    "## **IMPORTING MODULES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c047e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd22e38f",
   "metadata": {},
   "source": [
    "1. Data Understanding & Loading\n",
    "\n",
    "• Import data from all three sources (CSV, JSON, and SQL).\n",
    "\n",
    "• Display top 5 records and data info summary.\n",
    "\n",
    "• Identify data types, missing values, and inconsistent records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a52ff6",
   "metadata": {},
   "source": [
    "- **IMPORTING ALL FILES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e5d31d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing csv file\n",
    "\n",
    "data = pd.read_csv(\"users.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b05312c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing json file\n",
    "\n",
    "data_json = pd.read_json(\"sales.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a527b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing sql file\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"inventory.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e02d2ad",
   "metadata": {},
   "source": [
    "- **Displaying top 5 records and data info summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c31f32a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   user_id            200 non-null    object\n",
      " 1   name               200 non-null    object\n",
      " 2   age                200 non-null    int64 \n",
      " 3   gender             200 non-null    object\n",
      " 4   city               200 non-null    object\n",
      " 5   registration_date  200 non-null    object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 9.5+ KB\n",
      "Data Info: None\n"
     ]
    }
   ],
   "source": [
    "# From csv file\n",
    "\n",
    "print(f\"Data Info: {data.info()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0fc60408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Summary:               age\n",
      "count  200.000000\n",
      "mean    31.260000\n",
      "std      7.270951\n",
      "min     18.000000\n",
      "25%     26.000000\n",
      "50%     31.500000\n",
      "75%     35.250000\n",
      "max     53.000000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data Summary: {data.describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b60c0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Data:   user_id           name  age gender       city registration_date\n",
      "0   U0001  Vihaan Sharma   35  Other     Jaipur        08-09-2022\n",
      "1   U0002      Sai Reddy   30  Other  Hyderabad        24-11-2023\n",
      "2   U0003   Aarohi Gupta   37  Other     Indore        02-02-2022\n",
      "3   U0004    Aarav Gupta   44   Male    Kolkata        02-06-2023\n",
      "4   U0005    Sara Sharma   30  Other    Chennai        04-01-2024\n"
     ]
    }
   ],
   "source": [
    "print(f\"Top 5 Data: {data.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0cfaa39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types: user_id              object\n",
      "name                 object\n",
      "age                   int64\n",
      "gender               object\n",
      "city                 object\n",
      "registration_date    object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Missing Values: user_id              0\n",
      "name                 0\n",
      "age                  0\n",
      "gender               0\n",
      "city                 0\n",
      "registration_date    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Inconsistent Records: user_id              200\n",
      "name                 160\n",
      "age                   32\n",
      "gender                 3\n",
      "city                  20\n",
      "registration_date    188\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identifying data types\n",
    "\n",
    "print(f\"Data Types: {data.dtypes}\")\n",
    "print(\"\\n\")\n",
    "# Identifying missing values\n",
    "\n",
    "print(f\"Missing Values: {data.isnull().sum()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Identifying inconsistent records\n",
    "\n",
    "print(f\"Inconsistent Records: {data.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c310a",
   "metadata": {},
   "source": [
    "2. Data Cleaning\n",
    "\n",
    "• Handle missing numerical data using SimpleImputer (mean strategy).\n",
    "\n",
    "• Handle missing categorical data using most frequent imputation.\n",
    "\n",
    "• Apply KNN Imputer on multivariate data (optional enhancement).\n",
    "\n",
    "• Fix invalid or inconsistent entries (e.g., wrong date formats, negative prices, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0511e087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after handling missing numerical data:   user_id           name   age gender       city registration_date\n",
      "0   U0001  Vihaan Sharma  35.0  Other     Jaipur        08-09-2022\n",
      "1   U0002      Sai Reddy  30.0  Other  Hyderabad        24-11-2023\n",
      "2   U0003   Aarohi Gupta  37.0  Other     Indore        02-02-2022\n",
      "3   U0004    Aarav Gupta  44.0   Male    Kolkata        02-06-2023\n",
      "4   U0005    Sara Sharma  30.0  Other    Chennai        04-01-2024\n"
     ]
    }
   ],
   "source": [
    "# Handling missing numerical data using simple imputation (mean)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "numerical_cols = data.select_dtypes(include=[np.number]).columns\n",
    "data[numerical_cols] = imputer.fit_transform(data[numerical_cols])\n",
    "print(f\"Data after handling missing numerical data: {data.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c70c117d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after handling missing categorical data:   user_id           name   age gender       city registration_date\n",
      "0   U0001  Vihaan Sharma  35.0  Other     Jaipur        08-09-2022\n",
      "1   U0002      Sai Reddy  30.0  Other  Hyderabad        24-11-2023\n",
      "2   U0003   Aarohi Gupta  37.0  Other     Indore        02-02-2022\n",
      "3   U0004    Aarav Gupta  44.0   Male    Kolkata        02-06-2023\n",
      "4   U0005    Sara Sharma  30.0  Other    Chennai        04-01-2024\n"
     ]
    }
   ],
   "source": [
    "# Handling missing categorical data using simple imputation (most frequent)\n",
    "\n",
    "imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "data[categorical_cols] = imputer_cat.fit_transform(data[categorical_cols])\n",
    "print(f\"Data after handling missing categorical data: {data.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c76d9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after KNN Imputation:\n",
      "    age\n",
      "0  35.0\n",
      "1  30.0\n",
      "2  37.0\n",
      "3  44.0\n",
      "4  30.0\n"
     ]
    }
   ],
   "source": [
    "# Applying KNN imputer on multivariate data\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_data = data[numeric_cols]\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "numeric_imputed = imputer.fit_transform(numeric_data)\n",
    "\n",
    "numeric_imputed = pd.DataFrame(numeric_imputed, columns=numeric_cols)\n",
    "print(\"Data after KNN Imputation:\")\n",
    "print(numeric_imputed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6368386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after fixing invalid entries:   user_id           name   age gender       city registration_date\n",
      "0   U0001  Vihaan Sharma  35.0  Other     Jaipur        2022-08-09\n",
      "1   U0002      Sai Reddy  30.0  Other  Hyderabad               NaT\n",
      "2   U0003   Aarohi Gupta  37.0  Other     Indore        2022-02-02\n",
      "3   U0004    Aarav Gupta  44.0   Male    Kolkata        2023-02-06\n",
      "4   U0005    Sara Sharma  30.0  Other    Chennai        2024-04-01\n"
     ]
    }
   ],
   "source": [
    "# Fixing invalid and inconsistent data entries(e.g., wrong date formats, negative prices, etc)\n",
    "data['registration_date'] = pd.to_datetime(data['registration_date'], errors='coerce')\n",
    "print(f\"Data after fixing invalid entries: {data.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b09677e",
   "metadata": {},
   "source": [
    "3. Outlier Handling\n",
    "\n",
    "• Detect and remove outliers using Z-score and IQR method.\n",
    "\n",
    "• Compare both techniques and decide which is more suitable for this dataset.\n",
    "\n",
    "• Apply Winsorization for columns where removal isn't feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "427e9e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after removing outliers using Z-score method:   user_id           name   age gender       city registration_date\n",
      "0   U0001  Vihaan Sharma  35.0  Other     Jaipur        2022-08-09\n",
      "1   U0002      Sai Reddy  30.0  Other  Hyderabad               NaT\n",
      "2   U0003   Aarohi Gupta  37.0  Other     Indore        2022-02-02\n",
      "3   U0004    Aarav Gupta  44.0   Male    Kolkata        2023-02-06\n",
      "4   U0005    Sara Sharma  30.0  Other    Chennai        2024-04-01\n",
      "\n",
      "\n",
      "Data after removing outliers using IQR method:   user_id           name   age gender       city registration_date\n",
      "0   U0001  Vihaan Sharma  35.0  Other     Jaipur        2022-08-09\n",
      "1   U0002      Sai Reddy  30.0  Other  Hyderabad               NaT\n",
      "2   U0003   Aarohi Gupta  37.0  Other     Indore        2022-02-02\n",
      "3   U0004    Aarav Gupta  44.0   Male    Kolkata        2023-02-06\n",
      "4   U0005    Sara Sharma  30.0  Other    Chennai        2024-04-01\n"
     ]
    }
   ],
   "source": [
    "# Detecting and removing outliers using Z-score method and IQR method\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "z_scores = np.abs(stats.zscore(data.select_dtypes(include=[np.number])))\n",
    "filtered_entries = (z_scores < 3).all(axis=1)\n",
    "data_no_outliers_z = data[filtered_entries]\n",
    "print(f\"Data after removing outliers using Z-score method: {data_no_outliers_z.head()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Detecting and removing outliers using IQR method\n",
    "\n",
    "Q1 = data.select_dtypes(include=[np.number]).quantile(0.25)\n",
    "Q3 = data.select_dtypes(include=[np.number]).quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "filtered_entries_iqr = ~((data.select_dtypes(include=[np.number]) < (Q1 - 1.5 * IQR)) |(data.select_dtypes(include=[np.number]) > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "data_no_outliers_iqr = data[filtered_entries_iqr]\n",
    "print(f\"Data after removing outliers using IQR method: {data_no_outliers_iqr.head()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "20c78984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Shape: (200, 6)\n",
      "Data Shape after Z-score Outlier Removal: (200, 6)\n",
      "Data Shape after IQR Outlier Removal: (198, 6)\n"
     ]
    }
   ],
   "source": [
    "# Compapring both the techniques and deciding which is more suitable for the dataset\n",
    "\n",
    "print(f\"Original Data Shape: {data.shape}\")\n",
    "print(f\"Data Shape after Z-score Outlier Removal: {data_no_outliers_z.shape}\")\n",
    "print(f\"Data Shape after IQR Outlier Removal: {data_no_outliers_iqr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a1cb6e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after Winsorization:   user_id           name   age gender       city registration_date\n",
      "0   U0001  Vihaan Sharma  35.0  Other     Jaipur        2022-08-09\n",
      "1   U0002      Sai Reddy  30.0  Other  Hyderabad               NaT\n",
      "2   U0003   Aarohi Gupta  37.0  Other     Indore        2022-02-02\n",
      "3   U0004    Aarav Gupta  44.0   Male    Kolkata        2023-02-06\n",
      "4   U0005    Sara Sharma  30.0  Other    Chennai        2024-04-01\n"
     ]
    }
   ],
   "source": [
    "# Applying winzorization for columns where removal isnt feasible\n",
    "\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "winsorized_data = data.copy()\n",
    "numeric_cols = winsorized_data.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    winsorized_data[col] = winsorize(winsorized_data[col], limits=[0.05, 0.05])\n",
    "print(f\"Data after Winsorization: {winsorized_data.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b589d10e",
   "metadata": {},
   "source": [
    "4. Data Transformation\n",
    "\n",
    "• Convert date columns into separate day, month, year features.\n",
    "\n",
    "- Encode categorical variables using:\n",
    "    \n",
    "    - Label Encoding for binary columns.\n",
    "    - One-Hot Encoding for nominal columns.\n",
    "    - Ordinal Encoding for ordered categorical variables.\n",
    "\n",
    "• Apply binning (e.g., segment customers into spending groups: Low, Medium, High).\n",
    "\n",
    "• Apply log and square root transformations to normalize skewed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "22fa2c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after extracting date components:   user_id           name   age gender       city registration_date  \\\n",
      "0   U0001  Vihaan Sharma  35.0  Other     Jaipur        2022-08-09   \n",
      "1   U0002      Sai Reddy  30.0  Other  Hyderabad               NaT   \n",
      "2   U0003   Aarohi Gupta  37.0  Other     Indore        2022-02-02   \n",
      "3   U0004    Aarav Gupta  44.0   Male    Kolkata        2023-02-06   \n",
      "4   U0005    Sara Sharma  30.0  Other    Chennai        2024-04-01   \n",
      "\n",
      "   registration_day  registration_month  registration_year  \n",
      "0               9.0                 8.0             2022.0  \n",
      "1               NaN                 NaN                NaN  \n",
      "2               2.0                 2.0             2022.0  \n",
      "3               6.0                 2.0             2023.0  \n",
      "4               1.0                 4.0             2024.0  \n"
     ]
    }
   ],
   "source": [
    "# Converting date columns into separate day, month, year columns\n",
    "\n",
    "data['registration_day'] = data['registration_date'].dt.day\n",
    "data['registration_month'] = data['registration_date'].dt.month\n",
    "data['registration_year'] = data['registration_date'].dt.year\n",
    "print(f\"Data after extracting date components: {data.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5dbb5a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after Label Encoding:   user_id           name   age gender       city registration_date  \\\n",
      "0   U0001  Vihaan Sharma  35.0  Other     Jaipur        2022-08-09   \n",
      "1   U0002      Sai Reddy  30.0  Other  Hyderabad               NaT   \n",
      "2   U0003   Aarohi Gupta  37.0  Other     Indore        2022-02-02   \n",
      "3   U0004    Aarav Gupta  44.0   Male    Kolkata        2023-02-06   \n",
      "4   U0005    Sara Sharma  30.0  Other    Chennai        2024-04-01   \n",
      "\n",
      "   registration_day  registration_month  registration_year  \n",
      "0               9.0                 8.0             2022.0  \n",
      "1               NaN                 NaN                NaN  \n",
      "2               2.0                 2.0             2022.0  \n",
      "3               6.0                 2.0             2023.0  \n",
      "4               1.0                 4.0             2024.0  \n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical variables using:\n",
    "\n",
    "# Lable Encoding for binary columns.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "binary_cols = [col for col in data.select_dtypes(include=['object']).columns if data[col].nunique() == 2]\n",
    "for col in binary_cols:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "print(f\"Data after Label Encoding: {data.head()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d973856d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after One-Hot Encoding:     age registration_date  registration_day  registration_month  \\\n",
      "0  35.0        2022-08-09               9.0                 8.0   \n",
      "1  30.0               NaT               NaN                 NaN   \n",
      "2  37.0        2022-02-02               2.0                 2.0   \n",
      "3  44.0        2023-02-06               6.0                 2.0   \n",
      "4  30.0        2024-04-01               1.0                 4.0   \n",
      "\n",
      "   registration_year  user_id_U0002  user_id_U0003  user_id_U0004  \\\n",
      "0             2022.0            0.0            0.0            0.0   \n",
      "1                NaN            1.0            0.0            0.0   \n",
      "2             2022.0            0.0            1.0            0.0   \n",
      "3             2023.0            0.0            0.0            1.0   \n",
      "4             2024.0            0.0            0.0            0.0   \n",
      "\n",
      "   user_id_U0005  user_id_U0006  ...  city_Kolkata  city_Lucknow  city_Mumbai  \\\n",
      "0            0.0            0.0  ...           0.0           0.0          0.0   \n",
      "1            0.0            0.0  ...           0.0           0.0          0.0   \n",
      "2            0.0            0.0  ...           0.0           0.0          0.0   \n",
      "3            0.0            0.0  ...           1.0           0.0          0.0   \n",
      "4            1.0            0.0  ...           0.0           0.0          0.0   \n",
      "\n",
      "   city_Nagpur  city_Patna  city_Pune  city_Surat  city_Thane  city_Vadodara  \\\n",
      "0          0.0         0.0        0.0         0.0         0.0            0.0   \n",
      "1          0.0         0.0        0.0         0.0         0.0            0.0   \n",
      "2          0.0         0.0        0.0         0.0         0.0            0.0   \n",
      "3          0.0         0.0        0.0         0.0         0.0            0.0   \n",
      "4          0.0         0.0        0.0         0.0         0.0            0.0   \n",
      "\n",
      "   city_Visakhapatnam  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n",
      "3                 0.0  \n",
      "4                 0.0  \n",
      "\n",
      "[5 rows x 384 columns]\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding for nominal columns.\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "nominal_cols = [col for col in data.select_dtypes(include=['object']).columns if data[col].nunique() > 2]\n",
    "ohe_data = pd.DataFrame(ohe.fit_transform(data[nominal_cols]), columns=ohe.get_feature_names_out(nominal_cols))\n",
    "data = pd.concat([data.drop(columns=nominal_cols), ohe_data], axis=1)\n",
    "print(f\"Data after One-Hot Encoding: {data.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1f725c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 'customer_loyalty_level' column for ordinal encoding - skipping.\n"
     ]
    }
   ],
   "source": [
    "# Ordinal Encoding for ordered categorical variables.\n",
    "# e.g., customer_loyalty_level with order Bronze < Silver < Gold < Platinum\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "if 'customer_loyalty_level' in data.columns:\n",
    "    mapping = [['Bronze', 'Silver', 'Gold', 'Platinum']]\n",
    "    oe = OrdinalEncoder(categories=mapping)\n",
    "    data['customer_loyalty_level_encoded'] = oe.fit_transform(data[['customer_loyalty_level']])\n",
    "else:\n",
    "    print(\"No 'customer_loyalty_level' column for ordinal encoding - skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "58378416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after Binning:   transaction_id user_id product_id  amount payment_type       date  \\\n",
      "0        T000001   U0024       P015   67.67       Wallet 2023-02-12   \n",
      "1        T000002   U0196       P044   76.44          UPI 2023-03-24   \n",
      "2        T000003   U0196       P049  104.57   Debit Card 2025-08-21   \n",
      "3        T000004   U0133       P042  102.75  Net Banking 2024-07-23   \n",
      "4        T000005   U0047       P038   23.89  Net Banking 2025-10-04   \n",
      "\n",
      "  spending_group_q  \n",
      "0           Medium  \n",
      "1             High  \n",
      "2             High  \n",
      "3             High  \n",
      "4              Low  \n"
     ]
    }
   ],
   "source": [
    "# Applying binning (e.g., segment customers into spending groups: Low, Medium, High).\n",
    "\n",
    "data_json['spending_group_q'] = pd.qcut(data_json['amount'].fillna(data_json['amount'].mean()), q=3, labels=['Low', 'Medium', 'High'])\n",
    "print(f\"Data after Binning: {data_json.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bcd88945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after Transformations:     age registration_date  registration_day  registration_month  \\\n",
      "0  35.0        2022-08-09               9.0                 8.0   \n",
      "1  30.0               NaT               NaN                 NaN   \n",
      "2  37.0        2022-02-02               2.0                 2.0   \n",
      "3  44.0        2023-02-06               6.0                 2.0   \n",
      "4  30.0        2024-04-01               1.0                 4.0   \n",
      "\n",
      "   registration_year  user_id_U0002  user_id_U0003  user_id_U0004  \\\n",
      "0             2022.0            0.0            0.0            0.0   \n",
      "1                NaN            1.0            0.0            0.0   \n",
      "2             2022.0            0.0            1.0            0.0   \n",
      "3             2023.0            0.0            0.0            1.0   \n",
      "4             2024.0            0.0            0.0            0.0   \n",
      "\n",
      "   user_id_U0005  user_id_U0006  ...  city_Mumbai  city_Nagpur  city_Patna  \\\n",
      "0            0.0            0.0  ...          0.0          0.0         0.0   \n",
      "1            0.0            0.0  ...          0.0          0.0         0.0   \n",
      "2            0.0            0.0  ...          0.0          0.0         0.0   \n",
      "3            0.0            0.0  ...          0.0          0.0         0.0   \n",
      "4            1.0            0.0  ...          0.0          0.0         0.0   \n",
      "\n",
      "   city_Pune  city_Surat  city_Thane  city_Vadodara  city_Visakhapatnam  \\\n",
      "0        0.0         0.0         0.0            0.0                 0.0   \n",
      "1        0.0         0.0         0.0            0.0                 0.0   \n",
      "2        0.0         0.0         0.0            0.0                 0.0   \n",
      "3        0.0         0.0         0.0            0.0                 0.0   \n",
      "4        0.0         0.0         0.0            0.0                 0.0   \n",
      "\n",
      "    age_log  age_sqrt  \n",
      "0  3.583519  5.916080  \n",
      "1  3.433987  5.477226  \n",
      "2  3.637586  6.082763  \n",
      "3  3.806662  6.633250  \n",
      "4  3.433987  5.477226  \n",
      "\n",
      "[5 rows x 386 columns]\n"
     ]
    }
   ],
   "source": [
    "# Applying log and square root transformations to normalize skewed data.\n",
    "skewed_cols = data.select_dtypes(include=[np.number]).columns\n",
    "for col in skewed_cols:\n",
    "    if (data[col] > 0).all():\n",
    "        data[f'{col}_log'] = np.log(data[col] + 1)\n",
    "        data[f'{col}_sqrt'] = np.sqrt(data[col])\n",
    "print(f\"Data after Transformations: {data.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b1dd8",
   "metadata": {},
   "source": [
    "5. Feature Scaling\n",
    "\n",
    "• Use StandardScaler and MinMaxScaler to scale numerical features.\n",
    "\n",
    "• Compare the effect of scaling using summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cd7dba8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after Standard Scaling:         age registration_date  registration_day  registration_month  \\\n",
      "0  0.515666        2022-08-09          0.825118            0.380091   \n",
      "1 -0.173727               NaT               NaN                 NaN   \n",
      "2  0.791424        2022-02-02         -1.203465           -1.330320   \n",
      "3  1.756575        2023-02-06         -0.044275           -1.330320   \n",
      "4 -0.173727        2024-04-01         -1.493263           -0.760183   \n",
      "\n",
      "   registration_year  user_id_U0002  user_id_U0003  user_id_U0004  \\\n",
      "0          -0.968400      -0.070888      -0.070888      -0.070888   \n",
      "1                NaN      14.106736      -0.070888      -0.070888   \n",
      "2          -0.968400      -0.070888      14.106736      -0.070888   \n",
      "3           0.276686      -0.070888      -0.070888      14.106736   \n",
      "4           1.521772      -0.070888      -0.070888      -0.070888   \n",
      "\n",
      "   user_id_U0005  user_id_U0006  ...  city_Mumbai  city_Nagpur  city_Patna  \\\n",
      "0      -0.070888      -0.070888  ...    -0.190445    -0.217072   -0.252646   \n",
      "1      -0.070888      -0.070888  ...    -0.190445    -0.217072   -0.252646   \n",
      "2      -0.070888      -0.070888  ...    -0.190445    -0.217072   -0.252646   \n",
      "3      -0.070888      -0.070888  ...    -0.190445    -0.217072   -0.252646   \n",
      "4      14.106736      -0.070888  ...    -0.190445    -0.217072   -0.252646   \n",
      "\n",
      "   city_Pune  city_Surat  city_Thane  city_Vadodara  city_Visakhapatnam  \\\n",
      "0  -0.217072   -0.160128   -0.217072      -0.274352           -0.175863   \n",
      "1  -0.217072   -0.160128   -0.217072      -0.274352           -0.175863   \n",
      "2  -0.217072   -0.160128   -0.217072      -0.274352           -0.175863   \n",
      "3  -0.217072   -0.160128   -0.217072      -0.274352           -0.175863   \n",
      "4  -0.217072   -0.160128   -0.217072      -0.274352           -0.175863   \n",
      "\n",
      "    age_log  age_sqrt  \n",
      "0  0.588073  0.556828  \n",
      "1 -0.059989 -0.116002  \n",
      "2  0.822397  0.812378  \n",
      "3  1.555165  1.656358  \n",
      "4 -0.059989 -0.116002  \n",
      "\n",
      "[5 rows x 386 columns]\n"
     ]
    }
   ],
   "source": [
    "# Using StandardScaler to scale numerical features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "print(f\"Data after Standard Scaling: {data.head()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3410362f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after Min-Max Scaling:         age registration_date  registration_day  registration_month  \\\n",
      "0  0.485714        2022-08-09          0.727273            0.636364   \n",
      "1  0.342857               NaT               NaN                 NaN   \n",
      "2  0.542857        2022-02-02          0.090909            0.090909   \n",
      "3  0.742857        2023-02-06          0.454545            0.090909   \n",
      "4  0.342857        2024-04-01          0.000000            0.272727   \n",
      "\n",
      "   registration_year  user_id_U0002  user_id_U0003  user_id_U0004  \\\n",
      "0                0.0            0.0            0.0            0.0   \n",
      "1                NaN            1.0            0.0            0.0   \n",
      "2                0.0            0.0            1.0            0.0   \n",
      "3                0.5            0.0            0.0            1.0   \n",
      "4                1.0            0.0            0.0            0.0   \n",
      "\n",
      "   user_id_U0005  user_id_U0006  ...  city_Mumbai  city_Nagpur  city_Patna  \\\n",
      "0            0.0            0.0  ...          0.0          0.0         0.0   \n",
      "1            0.0            0.0  ...          0.0          0.0         0.0   \n",
      "2            0.0            0.0  ...          0.0          0.0         0.0   \n",
      "3            0.0            0.0  ...          0.0          0.0         0.0   \n",
      "4            1.0            0.0  ...          0.0          0.0         0.0   \n",
      "\n",
      "   city_Pune  city_Surat  city_Thane  city_Vadodara  city_Visakhapatnam  \\\n",
      "0        0.0         0.0         0.0            0.0                 0.0   \n",
      "1        0.0         0.0         0.0            0.0                 0.0   \n",
      "2        0.0         0.0         0.0            0.0                 0.0   \n",
      "3        0.0         0.0         0.0            0.0                 0.0   \n",
      "4        0.0         0.0         0.0            0.0                 0.0   \n",
      "\n",
      "    age_log  age_sqrt  \n",
      "0  0.611826  0.550932  \n",
      "1  0.468671  0.406452  \n",
      "2  0.663588  0.605808  \n",
      "3  0.825454  0.787040  \n",
      "4  0.468671  0.406452  \n",
      "\n",
      "[5 rows x 386 columns]\n"
     ]
    }
   ],
   "source": [
    "# Using MinMaxScaler to scale numerical features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "print(f\"Data after Min-Max Scaling: {data.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "435d49a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics after Standard Scaling:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>registration_date</th>\n",
       "      <th>registration_day</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>user_id_U0002</th>\n",
       "      <th>user_id_U0003</th>\n",
       "      <th>user_id_U0004</th>\n",
       "      <th>user_id_U0005</th>\n",
       "      <th>user_id_U0006</th>\n",
       "      <th>...</th>\n",
       "      <th>city_Mumbai</th>\n",
       "      <th>city_Nagpur</th>\n",
       "      <th>city_Patna</th>\n",
       "      <th>city_Pune</th>\n",
       "      <th>city_Surat</th>\n",
       "      <th>city_Thane</th>\n",
       "      <th>city_Vadodara</th>\n",
       "      <th>city_Visakhapatnam</th>\n",
       "      <th>age_log</th>\n",
       "      <th>age_sqrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>72</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.378857</td>\n",
       "      <td>2023-04-06 19:00:00</td>\n",
       "      <td>0.468434</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.481923</td>\n",
       "      <td>0.431362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-01-06 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.228571</td>\n",
       "      <td>2022-08-27 00:00:00</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.336412</td>\n",
       "      <td>0.281938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.385714</td>\n",
       "      <td>2023-02-08 12:00:00</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513796</td>\n",
       "      <td>0.450924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.492857</td>\n",
       "      <td>2023-12-05 06:00:00</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.618384</td>\n",
       "      <td>0.557839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2024-12-03 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.207741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.321140</td>\n",
       "      <td>0.404397</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184241</td>\n",
       "      <td>0.207824</td>\n",
       "      <td>0.238083</td>\n",
       "      <td>0.207824</td>\n",
       "      <td>0.156517</td>\n",
       "      <td>0.207824</td>\n",
       "      <td>0.255787</td>\n",
       "      <td>0.171015</td>\n",
       "      <td>0.221451</td>\n",
       "      <td>0.215274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              age    registration_date  registration_day  registration_month  \\\n",
       "count  200.000000                   72         72.000000           72.000000   \n",
       "mean     0.378857  2023-04-06 19:00:00          0.468434            0.515152   \n",
       "min      0.000000  2022-01-06 00:00:00          0.000000            0.000000   \n",
       "25%      0.228571  2022-08-27 00:00:00          0.181818            0.272727   \n",
       "50%      0.385714  2023-02-08 12:00:00          0.454545            0.545455   \n",
       "75%      0.492857  2023-12-05 06:00:00          0.727273            0.818182   \n",
       "max      1.000000  2024-12-03 00:00:00          1.000000            1.000000   \n",
       "std      0.207741                  NaN          0.315900            0.321140   \n",
       "\n",
       "       registration_year  user_id_U0002  user_id_U0003  user_id_U0004  \\\n",
       "count          72.000000     200.000000     200.000000     200.000000   \n",
       "mean            0.388889       0.005000       0.005000       0.005000   \n",
       "min             0.000000       0.000000       0.000000       0.000000   \n",
       "25%             0.000000       0.000000       0.000000       0.000000   \n",
       "50%             0.500000       0.000000       0.000000       0.000000   \n",
       "75%             0.500000       0.000000       0.000000       0.000000   \n",
       "max             1.000000       1.000000       1.000000       1.000000   \n",
       "std             0.404397       0.070711       0.070711       0.070711   \n",
       "\n",
       "       user_id_U0005  user_id_U0006  ...  city_Mumbai  city_Nagpur  \\\n",
       "count     200.000000     200.000000  ...   200.000000   200.000000   \n",
       "mean        0.005000       0.005000  ...     0.035000     0.045000   \n",
       "min         0.000000       0.000000  ...     0.000000     0.000000   \n",
       "25%         0.000000       0.000000  ...     0.000000     0.000000   \n",
       "50%         0.000000       0.000000  ...     0.000000     0.000000   \n",
       "75%         0.000000       0.000000  ...     0.000000     0.000000   \n",
       "max         1.000000       1.000000  ...     1.000000     1.000000   \n",
       "std         0.070711       0.070711  ...     0.184241     0.207824   \n",
       "\n",
       "       city_Patna   city_Pune  city_Surat  city_Thane  city_Vadodara  \\\n",
       "count  200.000000  200.000000  200.000000  200.000000     200.000000   \n",
       "mean     0.060000    0.045000    0.025000    0.045000       0.070000   \n",
       "min      0.000000    0.000000    0.000000    0.000000       0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000       0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000       0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000       0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000       1.000000   \n",
       "std      0.238083    0.207824    0.156517    0.207824       0.255787   \n",
       "\n",
       "       city_Visakhapatnam     age_log    age_sqrt  \n",
       "count          200.000000  200.000000  200.000000  \n",
       "mean             0.030000    0.481923    0.431362  \n",
       "min              0.000000    0.000000    0.000000  \n",
       "25%              0.000000    0.336412    0.281938  \n",
       "50%              0.000000    0.513796    0.450924  \n",
       "75%              0.000000    0.618384    0.557839  \n",
       "max              1.000000    1.000000    1.000000  \n",
       "std              0.171015    0.221451    0.215274  \n",
       "\n",
       "[8 rows x 386 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing the effect of scaling using summary statistics.\n",
    "print(\"Summary Statistics after Standard Scaling:\")\n",
    "(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd2b95a",
   "metadata": {},
   "source": [
    "6. Feature Construction\n",
    "\n",
    "- Create new features such as:\n",
    "    - Average monthly spend per customer.\n",
    "    - Frequency of purchase.\n",
    "    - Days since last purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "427b4ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after creating new features:         age registration_date  registration_day  registration_month  \\\n",
      "0  0.485714        2022-08-09          0.727273            0.636364   \n",
      "1  0.342857               NaT               NaN                 NaN   \n",
      "2  0.542857        2022-02-02          0.090909            0.090909   \n",
      "3  0.742857        2023-02-06          0.454545            0.090909   \n",
      "4  0.342857        2024-04-01          0.000000            0.272727   \n",
      "\n",
      "   registration_year  user_id_U0002  user_id_U0003  user_id_U0004  \\\n",
      "0                0.0            0.0            0.0            0.0   \n",
      "1                NaN            1.0            0.0            0.0   \n",
      "2                0.0            0.0            1.0            0.0   \n",
      "3                0.5            0.0            0.0            1.0   \n",
      "4                1.0            0.0            0.0            0.0   \n",
      "\n",
      "   user_id_U0005  user_id_U0006  ...  city_Nagpur  city_Patna  city_Pune  \\\n",
      "0            0.0            0.0  ...          0.0         0.0        0.0   \n",
      "1            0.0            0.0  ...          0.0         0.0        0.0   \n",
      "2            0.0            0.0  ...          0.0         0.0        0.0   \n",
      "3            0.0            0.0  ...          0.0         0.0        0.0   \n",
      "4            1.0            0.0  ...          0.0         0.0        0.0   \n",
      "\n",
      "   city_Surat  city_Thane  city_Vadodara  city_Visakhapatnam   age_log  \\\n",
      "0         0.0         0.0            0.0                 0.0  0.611826   \n",
      "1         0.0         0.0            0.0                 0.0  0.468671   \n",
      "2         0.0         0.0            0.0                 0.0  0.663588   \n",
      "3         0.0         0.0            0.0                 0.0  0.825454   \n",
      "4         0.0         0.0            0.0                 0.0  0.468671   \n",
      "\n",
      "   age_sqrt  registration_months  \n",
      "0  0.550932         24310.363636  \n",
      "1  0.406452                  NaN  \n",
      "2  0.605808         24310.909091  \n",
      "3  0.787040         24304.909091  \n",
      "4  0.406452         24298.727273  \n",
      "\n",
      "[5 rows x 387 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhruv\\AppData\\Local\\Temp\\ipykernel_3192\\679014860.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['registration_months'] = (datetime.now().year - data['registration_year']) * 12 + (datetime.now().month - data['registration_month'])\n"
     ]
    }
   ],
   "source": [
    "# Creating new features such as:\n",
    "    # - Average monthly spend per customer.\n",
    "from datetime import datetime\n",
    "data['registration_months'] = (datetime.now().year - data['registration_year']) * 12 + (datetime.now().month - data['registration_month'])\n",
    "print(f\"Data after creating new features: {data.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6a0143b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of Purchase Data:   user_id  purchase_frequency\n",
      "0   U0001                   3\n",
      "1   U0002                   6\n",
      "2   U0003                   4\n",
      "3   U0004                   3\n",
      "4   U0005                   6\n"
     ]
    }
   ],
   "source": [
    "# Frequency of purchase.\n",
    "\n",
    "freq_df = data_json.groupby('user_id').size().reset_index(name='purchase_frequency')\n",
    "print(f\"Frequency of Purchase Data: {freq_df.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d24e96fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days Since Last Purchase Data:   user_id last_purchase_date  days_since_last_purchase\n",
      "0   U0001         2024-08-20                       461\n",
      "1   U0002         2024-04-27                       576\n",
      "2   U0003         2025-11-01                        23\n",
      "3   U0004         2024-04-03                       600\n",
      "4   U0005         2025-06-22                       155\n"
     ]
    }
   ],
   "source": [
    "# Days since last purchase.\n",
    "\n",
    "last_purchase = data_json.groupby('user_id')['date'].max().reset_index(name='last_purchase_date')\n",
    "last_purchase['days_since_last_purchase'] = (pd.Timestamp.today() - last_purchase['last_purchase_date']).dt.days\n",
    "print(f\"Days Since Last Purchase Data: {last_purchase.head()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
